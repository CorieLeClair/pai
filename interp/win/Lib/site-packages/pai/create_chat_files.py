import nltk
import json
import enum

data = {'config': {
    "brain_file_type": "chat_file"
}, 'messages': {}}


class PaiChatFiles:
    class MessageDesc(enum.Enum):
        All = "All"
        Desc = "Ask001"

    @staticmethod
    def input_type(sent):
        # posts for chat
        posts = nltk.corpus.nps_chat.xml_posts()[:10000]

        # dialogue systems
        def dialogue_act_features(post):
            features = {}

            for word in nltk.word_tokenize(post):
                features['contains({})'.format(word.lower())] = True
            return features

        # training systems
        feature_sets = [(dialogue_act_features(post.text), post.get('class')) for post in posts]
        size = int(len(feature_sets) * 0.1)
        train_set, test_set = feature_sets[size:], feature_sets[:size]
        classifier = nltk.NaiveBayesClassifier.train(train_set)

        # returns the input type
        return classifier.classify(dialogue_act_features(sent))

    @staticmethod
    def create_json(message, response, desc):
        data["messages"][message] = []

        data['messages'][message].append({
            'message_contain_type': PaiChatFiles.input_type(message),
            'message_contain_string': message,
            'message_result_string': response,
            "message_result_type": PaiChatFiles.input_type(response),
            "desc": desc
        })

    @staticmethod
    def create_chat_file(file_result):
        print(data)
        json_file = open(file_result, "w")
        json.dump(data, json_file, indent=2)
